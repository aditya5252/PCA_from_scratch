{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15dc449",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def pca_scratch_high_dim(X,K,N):\n",
    "    '''\n",
    "    Here I apply High_Dimensional_PCA for dimensionality\n",
    "    reduction.\n",
    "    Function inputs N images each flattened to the dimension high_dim=10201 \n",
    "    which gets reduced to dimension low_dim=K.\n",
    "    X - N*high_dim\n",
    "    K - low_dim\n",
    "    N - no.of.samples\n",
    "    \n",
    "    function returns array of dim N*low_dim\n",
    "    '''\n",
    "    \n",
    "    '''sample_dim_matrix is of dimensions N*N \n",
    "    Its Eigenvectors will be of dimension N*1\n",
    "    Preserving top K principal components \n",
    "    ==> Keeping K eigenvectors corresponding to the top K eigenvalues\n",
    "    '''\n",
    "    mat_N=np.dot(X,X.T)/N\n",
    "    eig_val,eig_vec_N=LA.eig(mat_N)\n",
    "    increase_idx=np.argsort(eig_val)\n",
    "    decrease_idx=np.flip(increase_idx)\n",
    "    eig_vec_D_ls=[(  1/(N*eig_val[i])**0.5  )*np.dot(X.T,eig_vec_N[:,i]) for i in range(N)]\n",
    "    eig_vec_D=np.stack(eig_vec_D_ls)\n",
    "    K_feature_ls=[np.squeeze(np.dot(eig_vec_D[0:K],X[i].reshape(-1,1))) for i in range(N)]\n",
    "    K_feature_arr=np.stack(K_feature_ls)\n",
    "    return K_feature_arr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
